Zusammenfassung von Taxi:

Aufgabe:
Input -> Liste von Wort (btw. Term) Paare
Output -> Aus den Wörtern des Inputs soll eine Taxonomy gebaut werden.

Vorgehensweise:
Für die Patterns wird eine Große Menge an Daten gesammelt: Comoncrawl und Domainspecifisch. Aus diesen Datensätzen werden mittels lexico-syntactic patterns(PattaMaika, PatternSim, WebISA) hypernym kanditaten aus dem großen Datensatz generiert, die nicht mit über den Input hinausgehen.
Im Wesentlichen werden zwei Ansätze zur Hypernymerkennung verwendet.
Kandidaten werden erkannt durch:
	Substring matching: Alle Paarpermutation werden betrachtet und ein Wert berechnet, der 		beschreibt ob ein Term ein substring eines anderen Termes ist.
	
Patterns: Die aus dem großen Datensatz gefilterten Kandidaten werden benutzt und für diese ein 		Wert berechnet. Dieser ist eine Normalisierung der Frequenz der Paare(wie häufig die Paare in jedem Extraktor(also PattaMaika, PatternSim..) vorkommt. Dann wird der Durchschnitt über alle Extraktoren berechnet. Nun wird der endgültige pattern-based score für ein Paar durch die Differenz des Paares in beide Richtungen berechnet (um symetrische Beziehungen zu downranken). Dieser Patternbased score wird nun für alle Paare des Inputs berechnet und da dieser Score die Frequenz aller Paare im Datensatz vorraussetzt, ist das Crawlen von großen Datenmengen nötig.
 Hier befindet sich wohl der größte Spielraum der Arbeit, da wir schauen können ob man andere Informationen aus den Pattern extrahieren könnte.

Diese beiden Werte werden benutzt um Kandidaten herrauszufiltern. Dafür benutzen sie einen Klassifizierer (für die Englische Sprache) der beide Features benutzt und binär klassifiziert. Am besten war ihr linearSVM. Wir haben ein Feed-forward NN getestet, hat aber sehr schlechte Ergebnisse Produziert. F1 von 0.34(r:0.21, p: 0.98)  im Vergleich zum SVM mit 0.52(r: .37, p: 0.94). Interessant zu sehen ist, dass der Recall generell sehr schlecht ist, aber die Präzision sehr hoch. Das lässt vermuten, dass die gewählten Features eine sehr hohe Aussagekraft haben, quasi eine hirneichende Bedingung darstellt, aber viele Instanzen verfehlt werden. Hier wäre ein möglicher Ausbaupunkt, zusätzliche Features einzubauen.

Nach dem Pruning steps hat man nun die Paare die aus der Ursprünglichen n x n Anzahl an Kombinationen (mit n Länge des Vokabulars, direkt alle Wörter des Inputs) verblieben sind und als Hyperym relation registriert wurden. Den Graphen den man erhält muss dann noch gesäubert werden: Kreise entfernt werden, und sichergestellt sein, dass eine eindeutige Wurzel existiert. Dieser Schritt ist im Code nicht enthalten, scheint aber schon optimale Ergebnisse zu erzielen (Hat max. score für Struktur bekommen in der Auswertung).

